# -*- coding: utf-8 -*-
"""Amazon Product Recommendation Systems Code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KgUDz4-gX3NHu4-7hgrzWfY-EOPXra4f

# **Amazon Product Recommendation System Project**

--------------
## **Context:**
--------------

Today, information is growing exponentially with volume, velocity and variety throughout the globe. This has lead to information overload, and too many choices for the consumer of any business. It represents a real dilemma for these consumers and they often turn to denial. Recommender Systems are one of the best tools that help recommending products to consumers while they are browsing online. Providing personalized recommendations which is most relevant for the user is what's most likely to keep them engaged and help business.

E-commerce websites like Amazon, Walmart, Target and Etsy use different recommendation models to provide personalized suggestions to different users. These companies spend millions of dollars to come up with algorithmic techniques that can provide personalized recommendations to their users.

Amazon, for example, is well-known for its accurate selection of recommendations in its online site. Amazon's recommendation system is capable of intelligently analyzing and predicting customers' shopping preferences in order to offer them a list of recommended products. Amazon's recommendation algorithm is therefore a key element in using AI to improve the personalization of its website. For example, one of the baseline recommendation models that Amazon uses is item-to-item collaborative filtering, which scales to massive data sets and produces high-quality recommendations in real-time.

----------------
## **Objective:**
----------------

You are a Data Science Manager at Amazon, and have been given the task of building a recommendation system to recommend products to customers based on their previous ratings for other products. You have a collection of labeled data of Amazon reviews of products. The goal is to extract meaningful insights from the data and build a recommendation system that helps in recommending products to online consumers.

-----------------------------
## **Dataset:**
-----------------------------

The Amazon dataset contains the following attributes:

- **userId:** Every user identified with a unique id
- **productId:** Every product identified with a unique id
- **Rating:** The rating of the corresponding product by the corresponding user
- **timestamp:** Time of the rating. We **will not use this column** to solve the current problem
"""

from google.colab import drive
drive.mount('/content/drive')

"""**Installing surprise library**"""

!pip install surprise

"""## **Importing the necessary libraries and overview of the dataset**"""

import warnings
warnings.filterwarnings('ignore')

import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import seaborn as sns

from collections import defaultdict

from sklearn.metrics import mean_squared_error

"""### **Loading the data**
- Import the Dataset
- Add column names ['user_id', 'prod_id', 'rating', 'timestamp']
- Drop the column timestamp
- Copy the data to another DataFrame called **df**
"""

# Import the dataset (No headers in data)
df = pd.read_csv('/content/drive/MyDrive/ratings_Electronics.csv', header = None)

# Add column names
df.columns = ['user_id', 'prod_id', 'rating', 'timestamp']

# Getting rid of timestamp column
df = df.drop('timestamp', axis = 1)

# Copying data to another DataFrame
df_copy = df.copy(deep = True)

"""**As this dataset is very large and has 7,824,482 observations, it is not computationally possible to build a model using this. Moreover, many users have only rated a few products and also some products are rated by very few users. Hence, we can reduce the dataset by considering certain logical assumptions.**

Here, we will be taking users who have given at least 50 ratings, and the products that have at least 5 ratings, as when we shop online we prefer to have some number of ratings of a product.
"""

# Get the column containing the users
users = df.user_id

# Create a dictionary from users to their number of ratings
ratings_count = dict()

for user in users:

    # If we already have the user, just add 1 to their rating count
    if user in ratings_count:
        ratings_count[user] += 1

    # Otherwise, set their rating count to 1
    else:
        ratings_count[user] = 1

# We want our users to have at least 50 ratings to be considered
RATINGS_CUTOFF = 50

remove_users = []

for user, num_ratings in ratings_count.items():
    if num_ratings < RATINGS_CUTOFF:
        remove_users.append(user)

df = df.loc[ ~ df.user_id.isin(remove_users)]

# Get the column containing the products
prods = df.prod_id

# Create a dictionary from products to their number of ratings
ratings_count = dict()

for prod in prods:

    # If we already have the product, just add 1 to its rating count
    if prod in ratings_count:
        ratings_count[prod] += 1

    # Otherwise, set their rating count to 1
    else:
        ratings_count[prod] = 1

# We want our item to have at least 5 ratings to be considered
RATINGS_CUTOFF = 5

remove_users = []

for user, num_ratings in ratings_count.items():
    if num_ratings < RATINGS_CUTOFF:
        remove_users.append(user)

df_final = df.loc[~ df.prod_id.isin(remove_users)]

# Print a few rows of the imported dataset
df_final.head()

"""## **Exploratory Data Analysis**

### **Shape of the data**

### **Check the number of rows and columns and provide observations.**
"""

# Check the number of rows and columns
df_final.shape

"""The final condensed dataset contains 65290 entries, each with a corresponding user ID, product ID, and rating.

### **Data types**
"""

# Check Data types
df_final.info()

"""The dataset has two object-type (categorical) variables, the user ID and product ID, and one float type variable (the rating).

### **Checking for missing values**
"""

# Check for missing values present
df_final.isnull().sum()

"""None of the entries in the dataset are missing values.

### **Summary Statistics**
"""

# Summary statistics of 'rating' variable
df_final.describe()

"""The distribution of ratings in the condensed dataset appears to be left skewed with a mean rating of about 4.3 and ratings ranging from 1 to 5. The upper half of the data is all 5 ratings.

### **Checking the rating distribution**
"""

# Distribution of ratings

# Defining figure size and variable to plot
plt.figure(figsize = (12, 4))
sns.countplot(x="rating", data=df_final)

# Title and Axes Labels
plt.tick_params(labelsize = 10)
plt.title("Distribution of Ratings ", fontsize = 10)
plt.xlabel("Ratings", fontsize = 10)
plt.ylabel("Number of Ratings", fontsize = 10)
plt.show()

"""As described previously based on the summary statistics, the distribution of ratings is clearly left skewed and unimodal, peaking at a rating of 5. Ratings range from 1 to 5, and there do not appear to be any outliers. The majority of the products were rated 5.

### **Checking the number of unique users and items in the dataset**
"""

# Number of total rows in the data and number of unique user id and product id in the data
df_final['user_id'].nunique(), df_final['prod_id'].nunique()

"""There are 1540 unique users that rated products in this dataset and 5689 unique product.

### **Users with the most number of ratings**
"""

# Top 10 users based on the number of ratings
df_final['user_id'].value_counts().head(10)

"""User ADLVFFE4VBT8 has the most ratings of all users in the dataset at 295 ratings.

## **Model 1: Rank Based Recommendation System**
"""

# Calculate the average rating for each product
average_rating = df.groupby('prod_id')['rating'].mean()
# Calculate the count of ratings for each product
count_rating = df.groupby('prod_id')['rating'].count()
# Create a dataframe with calculated average and count of ratings
final_rating = pd.DataFrame({'avg_rating':average_rating, 'rating_count':count_rating})
# Sort the dataframe by average of ratings in the descending order
final_rating = final_rating.sort_values(by='avg_rating', ascending=False)

# See the first five records of the "final_rating" dataset
final_rating.head()

# Defining a function to get the top n products based on the highest average rating and minimum interactions
# Sorting values with respect to average rating
def top_n_products(data, n, min_interaction=100):
    # Finding Products with minimum number of interactions
    recommendations = data[data['rating_count'] > min_interaction]

    # Sorting values w.r.t. average rating
    recommendations = recommendations.sort_values(by='avg_rating', ascending=False)

    return recommendations.index[:n]

"""### **Recommending top 5 products with 50 minimum interactions based on popularity**"""

# Calling function to get top 5 list
res = list(top_n_products(final_rating, 5, 50))
# Product IDs
list_of_prods = []
for i in res:
    list_of_prods.append(df_final[df_final['prod_id']== str(i) ]['prod_id'].unique()[0])
list_of_prods

"""### **Recommending top 5 products with 100 minimum interactions based on popularity**"""

# Calling function to get top 5 list
res = list(top_n_products(final_rating, 5, 100))
# Product IDs
list_of_prods = []
for i in res:
    list_of_prods.append(df_final[df_final['prod_id']== str(i) ]['prod_id'].unique()[0])
list_of_prods

"""## **Model 2: Collaborative Filtering Recommendation System**

### **Building a baseline user-user similarity based recommendation system**

- Below, we are building **similarity-based recommendation systems** using `cosine` similarity and using **KNN to find similar users** which are the nearest neighbor to the given user.
"""

# To compute the accuracy of models
from surprise import accuracy

# Class is used to parse a file containing ratings, data should be in structure - user ; item ; rating
from surprise.reader import Reader

# Class for loading datasets
from surprise.dataset import Dataset

# For tuning model hyperparameters
from surprise.model_selection import GridSearchCV

# For splitting the rating data in train and test datasets
from surprise.model_selection import train_test_split

# For implementing similarity-based recommendation system
from surprise.prediction_algorithms.knns import KNNBasic

# For implementing matrix factorization based recommendation system
from surprise.prediction_algorithms.matrix_factorization import SVD

# for implementing K-Fold cross-validation
from surprise.model_selection import KFold

# For implementing clustering-based recommendation system
from surprise import CoClustering

"""**Relevant item:** An item (product in this case) that is actually **rated higher than the threshold rating** is relevant, if the **actual rating is below the threshold then it is a non-relevant item**.  

**Recommended item:** An item that's **predicted rating is higher than the threshold is a recommended item**, if the **predicted rating is below the threshold then that product will not be recommended to the user**.

**False Negative (FN):** It is the **frequency of relevant items that are not recommended to the user**. If the relevant items are not recommended to the user, then the user might not buy the product/item. This would result in the **loss of opportunity for the service provider**, which they would like to minimize.

**False Positive (FP):** It is the **frequency of recommended items that are actually not relevant**. In this case, the recommendation system is not doing a good job of finding and recommending the relevant items to the user. This would result in **loss of resources for the service provider**, which they would also like to minimize.

**Recall:** It is the **fraction of actually relevant items that are recommended to the user**, i.e., if out of 10 relevant products, 6 are recommended to the user then recall is 0.60. Higher the value of recall better is the model. It is one of the metrics to do the performance assessment of classification models.

**Precision:** It is the **fraction of recommended items that are relevant actually**, i.e., if out of 10 recommended items, 6 are found relevant by the user then precision is 0.60. The higher the value of precision better is the model. It is one of the metrics to do the performance assessment of classification models.

**While making a recommendation system, it becomes customary to look at the performance of the model. In terms of how many recommendations are relevant and vice-versa, below are some most used performance metrics used in the assessment of recommendation systems.**

### **Precision@k, Recall@ k, and F1-score@k**

**Precision@k** - It is the **fraction of recommended items that are relevant in `top k` predictions**. The value of k is the number of recommendations to be provided to the user. One can choose a variable number of recommendations to be given to a unique user.  


**Recall@k** - It is the **fraction of relevant items that are recommended to the user in `top k` predictions**.

**F1-score@k** - It is the **harmonic mean of Precision@k and Recall@k**. When **precision@k and recall@k both seem to be important** then it is useful to use this metric because it is representative of both of them.

### **Some useful functions**

- Below function takes the **recommendation model** as input and gives the **precision@k, recall@k, and F1-score@k** for that model.  
- To compute **precision and recall**, **top k** predictions are taken under consideration for each user.
- We will use the precision and recall to compute the F1-score.
"""

def precision_recall_at_k(model, k = 10, threshold = 3.5):
    """Return precision and recall at k metrics for each user"""

    # First map the predictions to each user
    user_est_true = defaultdict(list)

    # Making predictions on the test data
    predictions = model.test(testset)

    for uid, _, true_r, est, _ in predictions:
        user_est_true[uid].append((est, true_r))

    precisions = dict()
    recalls = dict()
    for uid, user_ratings in user_est_true.items():

        # Sort user ratings by estimated value
        user_ratings.sort(key = lambda x: x[0], reverse = True)

        # Number of relevant items
        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)

        # Number of recommended items in top k
        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])

        # Number of relevant and recommended items in top k
        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))
                              for (est, true_r) in user_ratings[:k])

        # Precision@K: Proportion of recommended items that are relevant
        # When n_rec_k is 0, Precision is undefined. Therefore, we are setting Precision to 0 when n_rec_k is 0

        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0

        # Recall@K: Proportion of relevant items that are recommended
        # When n_rel is 0, Recall is undefined. Therefore, we are setting Recall to 0 when n_rel is 0

        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0

    # Mean of all the predicted precisions are calculated.
    precision = round((sum(prec for prec in precisions.values()) / len(precisions)), 3)

    # Mean of all the predicted recalls are calculated.
    recall = round((sum(rec for rec in recalls.values()) / len(recalls)), 3)

    accuracy.rmse(predictions)

    print('Precision: ', precision) # Command to print the overall precision

    print('Recall: ', recall) # Command to print the overall recall

    print('F_1 score: ', round((2*precision*recall)/(precision+recall), 3)) # Formula to compute the F-1 score

"""Below we are loading the **`rating` dataset**, which is a **pandas DataFrame**, into a **different format called `surprise.dataset.DatasetAutoFolds`**, which is required by this library. To do this, we will be **using the classes `Reader` and `Dataset`.**"""

# Instantiating Reader scale with expected rating scale
reader = Reader(rating_scale=(1, 10))

# Loading the rating dataset
data = Dataset.load_from_df(df_final[['user_id', 'prod_id', 'rating']], reader)

# Splitting the data into train and test dataset
trainset, testset = train_test_split(data, test_size=0.3, random_state=42)

"""### **Building the user-user Similarity-based Recommendation System**"""

# Declaring the similarity options
sim_options = {'name': 'cosine',
               'user_based': True}
# Initialize the KNNBasic model using sim_options declared, Verbose = False, and setting random_state = 1
algo_knn_user = KNNBasic(sim_options=sim_options,verbose=False, random_state = 1)

# Fit the model on the training data
algo_knn_user.fit(trainset)

# Let us compute precision@k, recall@k, and f_1 score using the precision_recall_at_k function defined above
precision_recall_at_k(algo_knn_user)

"""We can observe that the baseline model has RMSE=1.0250 on the test set. We are getting a recall of ~0.78, which means out of all the relevant products, 78% are recommended. We are getting a precision of 0.86, which means out of all the recommended products, 86% are relevant. The F1 score of the baseline model is 0.82, indicating that mostly recommended products were relevant, and relevant products were recommended.

Let's now **predict rating for a user with `userId=A3LDPF5FMB782Z` and `productId=1400501466`** as shown below. Here the user has already interacted or watched the product with productId '1400501466' and given a rating of 5.
"""

# Predicting rating for a sample user with an interacted product
algo_knn_user.predict("A3LDPF5FMB782Z", "1400501466", r_ui=5, verbose=True)

"""We observe that the actual rating for this user-product pair is 5 and predicted rating is 3 by this similarity based baseline model, which is clearly not very accurate.

Below is the **list of users who have not seen the product with product id "1400501466"**.
"""

# Find unique user_id where prod_id is not equal to "1400501466"'
user_list = df_final[df_final['prod_id'] != '1400501466']['user_id'].unique()
user_list

"""* It can be observed from the above list that **user "A34BZM6S9L7QI4" has not seen the product with productId "1400501466"** as this userId is a part of the above list.

**Below we are predicting rating for `userId=A34BZM6S9L7QI4` and `prod_id=1400501466`.**
"""

# Predicting rating for a sample user with a non interacted product
algo_knn_user.predict("A34BZM6S9L7QI4", "1400501466", verbose=True)

"""The base model predicts that user A34BZM6S9L7QI4 will rate product 1400501466 a 4.29 out of 5.

### **Improving similarity-based recommendation system by tuning its hyperparameters**

Below, we will be tuning hyperparameters for the `KNNBasic` algorithm. Here are some of the hyperparameters of the KNNBasic algorithm:

- **k** (int) – The (max) number of neighbors to take into account for aggregation. Default is 40.
- **min_k** (int) – The minimum number of neighbors to take into account for aggregation. If there are not enough neighbors, the prediction is set to the global mean of all ratings. Default is 1.
- **sim_options** (dict) – A dictionary of options for the similarity measure. And there are four similarity measures available in surprise -
    - cosine
    - msd (default)
    - Pearson
    - Pearson baseline
"""

# Setting up parameter grid to tune the hyperparameters
param_grid = {'k': [20, 30, 40], 'min_k': [3, 6, 9],
              'sim_options': {'name': ['msd', 'cosine'],
                              'user_based': [True]}
              }
# Performing 3-fold cross-validation to tune the hyperparameters
gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse', 'mae'], cv=3, n_jobs=-1)
# Fitting the data
gs.fit(data)
# Best RMSE score
print(gs.best_score['rmse'])
# Combination of parameters that gave the best RMSE score
print(gs.best_params['rmse'])

"""Once the grid search is **complete**, we can get the **optimal values for each of those hyperparameters**.

Now, we build the **final model by using tuned values of the hyperparameters**, which we received by using **grid search cross-validation**.
"""

# Using the optimal similarity measure for user-user based collaborative filtering
sim_options = {'name': 'cosine',
               'user_based': True}
# Creating an instance of KNNBasic with optimal hyperparameter values
similarity_algo_optimized = KNNBasic(sim_options=sim_options, k=40, min_k=6, verbose=False)
# Training the algorithm on the trainset
similarity_algo_optimized.fit(trainset)
# Let us compute precision@k and recall@k also with k =10
precision_recall_at_k(similarity_algo_optimized)

"""After tuning hyperparameters, RMSE for the test set has reduced from 1.0250 to 0.9630. We can observe that after tuning the hyperparameters, the tuned model's F-1 score increased from 0.82 to 0.829 in comparison to the baseline model. As a result, we can say that the model's performance has improved overall after hyperparameter tuning.

### **Steps:**
- **Predict rating for the user with `userId="A3LDPF5FMB782Z"`, and `prod_id= "1400501466"` using the optimized model**
- **Predict rating for `userId="A34BZM6S9L7QI4"` who has not interacted with `prod_id ="1400501466"`, by using the optimized model**
- **Compare the output with the output from the baseline model**
"""

# Use sim_user_user_optimized model to recommend for userId "A3LDPF5FMB782Z" and productId 1400501466
similarity_algo_optimized.predict("A3LDPF5FMB782Z", "1400501466", r_ui=5, verbose=True)

# Use sim_user_user_optimized model to recommend for userId "A34BZM6S9L7QI4" and productId "1400501466"
similarity_algo_optimized.predict("A34BZM6S9L7QI4", "1400501466", verbose=True)

"""The rating prediction for user A3LDPF5FMB782Z, who has already interacted with product 1400501466 is much better at 4.29 as opposed to 3 in the baseline model (since the actual rating is 5). The rating prediction for user A34BZM6S9L7QI4, who has not interacted with this product, remained constant at 4.29.

### **Identifying similar users to a given user (nearest neighbors)**

We can also find out **similar users to a given user** or its **nearest neighbors** based on this KNNBasic algorithm. Below, we are finding the 5 most similar users to the first user in the list with internal id 0, based on the `msd` distance metric.
"""

# 0 is the inner id of the above user
similarity_algo_optimized.get_neighbors(0, k=5)

"""### **Implementing the recommendation algorithm based on optimized KNNBasic model**

Below we will be implementing a function where the input parameters are:

- data: A **rating** dataset
- user_id: A user id **against which we want the recommendations**
- top_n: The **number of products we want to recommend**
- algo: the algorithm we want to use **for predicting the ratings**
- The output of the function is a **set of top_n items** recommended for the given user_id based on the given algorithm
"""

def get_recommendations(data, user_id, top_n, algo):

    # Creating an empty list to store the recommended product ids
    recommendations = []

    # Creating an user item interactions matrix
    user_item_interactions_matrix = data.pivot(index = 'user_id', columns = 'prod_id', values = 'rating')

    # Extracting those product ids which the user_id has not interacted yet
    non_interacted_products = user_item_interactions_matrix.loc[user_id][user_item_interactions_matrix.loc[user_id].isnull()].index.tolist()

    # Looping through each of the product ids which user_id has not interacted yet
    for item_id in non_interacted_products:

        # Predicting the ratings for those non interacted product ids by this user
        est = algo.predict(user_id, item_id).est

        # Appending the predicted ratings
        recommendations.append((item_id, est))

    # Sorting the predicted ratings in descending order
    recommendations.sort(key = lambda x: x[1], reverse = True)

    return recommendations[:top_n] # Returing top n highest predicted rating products for this user

"""**Predicting top 5 products for userId = "A3LDPF5FMB782Z" with similarity based recommendation system**"""

# Making top 5 recommendations for user_id "A3LDPF5FMB782Z" with a similarity-based recommendation engine
recommendations = get_recommendations(df_final, 'A3LDPF5FMB782Z', 5, similarity_algo_optimized)

# Building the dataframe for above recommendations with columns "prod_id" and "predicted_ratings"
pd.DataFrame(recommendations, columns=['prod_id', 'predicted_ratings'])

"""### **Item-Item Similarity-based Collaborative Filtering Recommendation System**

* Above we have seen **similarity-based collaborative filtering** where similarity is calculated **between users**. Now let us look into similarity-based collaborative filtering where similarity is seen **between items**.
"""

# Declaring the similarity options
sim_options = {'name': 'cosine',
               'user_based': False}
# KNN algorithm is used to find desired similar items. Use random_state=1
algo_knn_item = KNNBasic(sim_options=sim_options,verbose=False, random_state = 1)
# Train the algorithm on the trainset, and predict ratings for the test set
algo_knn_item.fit(trainset)
# Let us compute precision@k, recall@k, and f_1 score with k = 10
precision_recall_at_k(algo_knn_item)

"""We can observe that the model has RMSE=1.0232 on the test set. We are getting a recall of ~0.76, which means out of all the relevant products, 76% are recommended. We are getting a precision of ~0.84, which means out of all the recommended products, 84% are relevant. The F1 score of the baseline model is 0.795. It indicates that mostly recommended products were relevant and relevant products were recommended.

Let's now **predict a rating for a user with `userId = A3LDPF5FMB782Z` and `prod_Id = 1400501466`** as shown below. Here the user has already interacted or watched the product with productId "1400501466".
"""

# Predicting rating for a sample user with an interacted product
algo_knn_item.predict("A3LDPF5FMB782Z", "1400501466", r_ui=5, verbose=True)

"""We observe that the actual rating for this user-product pair is 5 and predicted rating is 4.32 by this item-item similarity based system, which is more accurate than the optimized user-user similarity-based recommendation system.

Below we are **predicting rating for the `userId = A34BZM6S9L7QI4` and `prod_id = 1400501466`**.
"""

# Predicting rating for a sample user with a non interacted product
algo_knn_item.predict("A34BZM6S9L7QI4", "1400501466", verbose=True)

"""The model predicts that this user will rate the product 4.29 out of 5.

### **Hyperparameter tuning the item-item similarity-based model**
"""

# Setting up parameter grid to tune the hyperparameters
param_grid = {'k': [10,20,30], 'min_k': [3,6,9],
              'sim_options': {'name': ['msd', 'cosine'],
                              'user_based': [False]}
              }
# Performing 3-fold cross validation to tune the hyperparameters
grid_obj = GridSearchCV(KNNBasic, param_grid, measures=['rmse', 'mae'], cv=3)
# Fitting the data
grid_obj.fit(data)
# Find the best RMSE score
print(grid_obj.best_score['rmse'])
# Find the combination of parameters that gave the best RMSE score
print(grid_obj.best_params['rmse'])

"""### **Use the best parameters from GridSearchCV to build the optimized item-item similarity-based model. Compare the performance of the optimized model with the baseline model.**"""

# Using the optimal similarity measure for item-item based collaborative filtering
# Creating an instance of KNNBasic with optimal hyperparameter values
similarity_algo_optimized_item = KNNBasic(sim_options={'name': 'msd', 'user_based': False}, k=20, min_k=6,verbose=False)
# Training the algorithm on the trainset
similarity_algo_optimized_item.fit(trainset)
# Let us compute precision@k and recall@k, f1_score and RMSE
precision_recall_at_k(similarity_algo_optimized_item)

"""We observe that after tuning hyperparameters, RMSE for the test set has reduced to 0.9694 from 1.0232. F_1 score of the tuned model is also slightly better than the baseline model. So, the model performance has improved slightly after hyperparameter tuning."""

# Use sim_item_item_optimized model to recommend for userId "A3LDPF5FMB782Z" and productId "1400501466"
similarity_algo_optimized_item.predict("A3LDPF5FMB782Z", "1400501466", r_ui=5, verbose=True)

# Use sim_item_item_optimized model to recommend for userId "A34BZM6S9L7QI4" and productId "1400501466"
similarity_algo_optimized_item.predict("A34BZM6S9L7QI4", "1400501466", verbose=True)

"""The rating prediction for the user who has already interacted with the product has become more accurate at 4.70 compared to the actual rating of 5, while the rating for the user who has not interacted with the product remains unchanged at 4.29.

### **Identifying similar items to a given item (nearest neighbors)**

We can also find out **similar items** to a given item or its nearest neighbors based on this **KNNBasic algorithm**. Below we are finding the 5 most similar items to the item with internal id 0 based on the `msd` distance metric.
"""

similarity_algo_optimized_item.get_neighbors(0, k=5)

# Making top 5 recommendations for user_id A1A5KUIIIHFF4U with similarity-based recommendation engine.
recommendations = get_recommendations(df_final, "A1A5KUIIIHFF4U", 5, similarity_algo_optimized_item)

# Building the dataframe for above recommendations with columns "prod_id" and "predicted_ratings"
pd.DataFrame(recommendations, columns=['prod_id', 'predicted_ratings'])

"""### **Model 3: Model-Based Collaborative Filtering - Matrix Factorization**

Model-based Collaborative Filtering is a **personalized recommendation system**, the recommendations are based on the past behavior of the user and it is not dependent on any additional information. We use **latent features** to find recommendations for each user.

### Singular Value Decomposition (SVD)

SVD is used to **compute the latent features** from the **user-item matrix**. But SVD does not work when we **miss values** in the **user-item matrix**.
"""

# Using SVD matrix factorization. Use random_state = 1
svd = SVD(random_state=1)
# Training the algorithm on the trainset
svd.fit(trainset)
# Use the function precision_recall_at_k to compute precision@k, recall@k, F1-Score, and RMSE
precision_recall_at_k(svd)

"""We observe that the baseline F_1 score for the matrix factorization model on the test set is slightly higher in comparison to the F_1 score for the user-user similarity-based recommendation system and slightly lower in comparison to the optimized user-user similarity-based recommendation system. The result for SVD is better than both baseline and optimized item-item similarity-based recommendation systems."""

# Making prediction
svd.predict("A3LDPF5FMB782Z", "1400501466", r_ui=5, verbose=True)

"""The matrix factorization model predicts a rating of 4.07 for this user when their actual rating was 5. This particular prediction is the further off than all the models except the baseline user-user similarity-based recommendation system."""

# Making prediction
svd.predict("A34BZM6S9L7QI4", "1400501466", verbose=True)

"""The matrix factorization model predicts a rating of 4.39 for this user on this product the user has not interacted with.

### **Improving Matrix Factorization based recommendation system by tuning its hyperparameters**

Below we will be tuning only three hyperparameters:
- **n_epochs**: The number of iterations of the SGD algorithm.
- **lr_all**: The learning rate for all parameters.
- **reg_all**: The regularization term for all parameters.
"""

# Set the parameter space to tune
param_grid = {'n_epochs': [10, 20, 30], 'lr_all': [0.001, 0.005, 0.01],
              'reg_all': [0.2, 0.4, 0.6]}
# Performing 3-fold gridsearch cross-validation
gs_ = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3, n_jobs=-1)
# Fitting data
gs_.fit(data)
# Best RMSE score
print(gs_.best_score['rmse'])
# Combination of parameters that gave the best RMSE score
print(gs_.best_params['rmse'])

"""Now, we will **the build final model** by using **tuned values** of the hyperparameters, which we received using grid search cross-validation above."""

# Build the optimized SVD model using optimal hyperparameter search. Use random_state=1
svd_optimized = SVD(n_epochs=20, lr_all=0.01, reg_all=0.4, random_state=1)
# Train the algorithm on the trainset
svd_optimized=svd_optimized.fit(trainset)
# Use the function precision_recall_at_k to compute precision@k, recall@k, F1-Score, and RMSE
precision_recall_at_k(svd_optimized)

"""We observe that after tuning hyperparameters, the model performance has not improved by much. We can try other values for hyperparameters and see if we can get a better performance. However, here we will proceed with the existing model."""

# Use svd_algo_optimized model to recommend for userId "A3LDPF5FMB782Z" and productId "1400501466"
svd_optimized.predict("A3LDPF5FMB782Z", "1400501466", r_ui=5, verbose=True)

"""The rating prediction of the optimized matrix factorization model for this user with this product actually ends up being slightly less accurate (4.02 compared to 4.07), further supporting that the hyperparameter optimization did not help the model very much."""

# Use svd_algo_optimized model to recommend for userId "A34BZM6S9L7QI4" and productId "1400501466"
svd_optimized.predict("A34BZM6S9L7QI4", "1400501466", verbose=True)

"""The rating prediction of the optimized matrix factorization model for this user with the product they have not interacted with before changed from 4.39 to 4.11.

### **Conclusion and Recommendations**

In the Amazon Product Recommendation System project, several models were explored to provide personalized recommendations for users. The user-user similarity-based collaborative filtering model initially demonstrated decent predictive power, with an RMSE of 1.0250. After hyperparameter tuning, including optimizing the similarity measure and adjusting the number of neighbors, the model's RMSE was reduced to 0.9630. This improvement, though slight, was significant as it also led to an enhanced F1 score, indicating that the model was better at recommending relevant products. A precision of 0.86 and a recall of 0.783 before tuning showed that a large portion of relevant products was being recommended, and after tuning, these metrics reflected similar results with slight improvements, further solidifying the model's relevance for real-world use.

The item-item similarity-based model followed a similar trajectory. Initially, its RMSE on the test set was 1.0232, showing alignment with the baseline performance of the user-user model. However, after hyperparameter tuning, the RMSE dropped to 0.9694, closely matching the optimized user-user model’s results. The precision and recall for this model also improved slightly after tuning, indicating a better balance between recommending relevant items and ensuring the recommended items were meaningful to the user.

The matrix factorization model using SVD produced a more nuanced set of results. The baseline performance was stronger in some respects than the user-user and item-item models, with a slightly higher F1 score, demonstrating better general performance. However, when hyperparameter tuning was applied, the matrix factorization model's improvement was marginal, with the RMSE changing from 0.8995 to 0.8909 and precision and recall having minimal improvement. The optimization of parameters like n_epochs, lr_all, and reg_all did not yield a substantial performance increase, which suggests that further tuning or additional techniques might be necessary to realize the full potential of matrix factorization models for this recommendation task.

In conclusion, the user-user and item-item similarity-based collaborative filtering models both showed significant improvement after tuning, with reductions in RMSE and slight gains in precision and recall. These models are highly applicable for this type of recommendation system, providing a balance of precision and relevance. The matrix factorization model, despite its initial strong baseline performance, did not benefit as much from hyperparameter tuning, suggesting that it may not be as suitable for this dataset without further refinements. For future improvements, experimenting with different algorithms or incorporating more advanced techniques like hybrid recommendation systems could enhance the overall performance of the system. Implementing the optimized user-user and item-item models can significantly boost user engagement and satisfaction, boosting the chance of a purchase and exposing users to more products. Integrating these models into targeted marketing strategies, such as personalized email campaigns, could further amplify their impact. For the matrix factorization model, incorporating additional data or exploring hybrid models might yield better results. Expanding the models to other domains like movies or services could also broaden their use and enhance the user experience across Amazon's diverse platforms. Continuous monitoring and model refinement will be essential to maintain relevance as user preferences change.
"""